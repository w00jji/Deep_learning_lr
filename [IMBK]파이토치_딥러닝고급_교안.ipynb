{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### 1. 앙상블 ① - 이미지 학습모델 3개"],"metadata":{"id":"EJ1vqKKshGhU"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"aUXVCYWqhF9b","executionInfo":{"status":"ok","timestamp":1725930247727,"user_tz":-540,"elapsed":358,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torchvision.models import resnet18\n","\n","# ResNet18\n","class ResNetModel(nn.Module):\n","    def __init__(self):\n","        super(ResNetModel, self).__init__()\n","        # 3채널로 미리 학습 된거 안가져옴\n","        self.model = resnet18(pretrained=False)\n","        # 채널 1이 들어가기 때문에 첫번째 레이어 바꿔버림\n","        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        # 끝단에 클래스를 10개짜리로 분류 할 수 있는 레이어로 바꿈\n","        self.model.fc = nn.Linear(self.model.fc.in_features, 10)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","resnet_model = ResNetModel().to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nmgTwjzMc_i","outputId":"3475dade-1040-4620-cdb0-5356f33283ec","executionInfo":{"status":"ok","timestamp":1725930248637,"user_tz":-540,"elapsed":447,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["from torchvision.models import densenet121\n","\n","# DenseNet121 모델\n","class DenseNetModel(nn.Module):\n","    def __init__(self):\n","        super(DenseNetModel, self).__init__()\n","        self.model = densenet121(pretrained=False)\n","        self.model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.model.classifier = nn.Linear(self.model.classifier.in_features, 10)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","densenet_model = DenseNetModel().to(device)\n"],"metadata":{"id":"3uHGVOHVMg7R","executionInfo":{"status":"ok","timestamp":1725930249544,"user_tz":-540,"elapsed":447,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.conv1(x))\n","        x = nn.MaxPool2d(2, 2)(x)\n","        x = nn.ReLU()(self.conv2(x))\n","        x = nn.MaxPool2d(2, 2)(x)\n","        x = x.view(-1, 64 * 56 * 56)\n","        x = nn.ReLU()(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","cnn_model = CNNModel().to(device)\n"],"metadata":{"id":"PCleCQf_MjFZ","executionInfo":{"status":"ok","timestamp":1725930250294,"user_tz":-540,"elapsed":388,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","def train_model(model, optimizer, train_loader, epochs=1):\n","    model.train()\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for inputs, labels in tqdm(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n","\n","resnet_optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n","densenet_optimizer = optim.Adam(densenet_model.parameters(), lr=0.001)\n","cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n","\n","# 순차적으로 학습.\n","# ResNet\n","train_model(resnet_model, resnet_optimizer, train_loader)\n","\n","# DenseNet\n","train_model(densenet_model, densenet_optimizer, train_loader)\n","\n","# CNN\n","train_model(cnn_model, cnn_optimizer, train_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6r4nfWAoMkO5","outputId":"59b8f55e-1a42-420b-a9b1-ae835446f831","executionInfo":{"status":"ok","timestamp":1725931219568,"user_tz":-540,"elapsed":968871,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [03:30<00:00,  4.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.10419028171716428\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [10:38<00:00,  1.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.1191907719726851\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [01:59<00:00,  7.85it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.27463672904452596\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# 3개 모델 준비.\n","models = [resnet_model, densenet_model, cnn_model]\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, labels in tqdm(test_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # 이미지를 모델에 번갈아 가면서 줌 그러면 모델 3개에 대한 prediction값이 나옴\n","        # 모델 갯수, 배치사이즈, 10개 클래스 확률 =3, 64, 10\n","        outputs = [model(inputs) for model in models]\n","\n","        # 걔네들을 가져와서 쌓고, z축 방향으로 mean값 처리해서 평균 확률값으로 계산\n","        outputs = torch.mean(torch.stack(outputs), dim=0)\n","\n","        # 평균 예측 행렬 배치사이즈 X 평균 10개 클래스 확률을 max해서,\n","        # 배치 x 예측클래스 도출\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","print(f'Ensemble Accuracy: {100 * correct / total:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8JF7ucYMpei","outputId":"a9d03a89-241f-4c4d-c82b-d73a81f4b161","executionInfo":{"status":"ok","timestamp":1725931271672,"user_tz":-540,"elapsed":52108,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:52<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Ensemble Accuracy: 99.25%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### 실습1) 와인데이터를 통한 MLP 모델 3개 클래스 분류 앙상블\n","\n","각 모델을 튜닝하여 성능을 높여보자."],"metadata":{"id":"ZzFrgn-JO93u"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","data = pd.read_csv('wine.csv')"],"metadata":{"id":"WooRlcFRXpU0","executionInfo":{"status":"ok","timestamp":1725931273080,"user_tz":-540,"elapsed":1418,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["X = data.drop(columns=['class']).values\n","y = data[['class']].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","scaler = RobustScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"wlFGcoH5O-Vv","executionInfo":{"status":"ok","timestamp":1725931273081,"user_tz":-540,"elapsed":9,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class Model1(nn.Module):\n","    def __init__(self):\n","        super(Model1, self).__init__()\n","        self.fc1 = nn.Linear(12, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 1)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp_model1 = Model1()\n"],"metadata":{"id":"os8Sy9ISPBaJ","executionInfo":{"status":"ok","timestamp":1725931273081,"user_tz":-540,"elapsed":8,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class Model2(nn.Module):\n","    def __init__(self):\n","        super(Model2, self).__init__()\n","        self.fc1 = nn.Linear(12, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 1)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp_model2 = Model2()\n"],"metadata":{"id":"cbVqA4CeO_Fw","executionInfo":{"status":"ok","timestamp":1725931273081,"user_tz":-540,"elapsed":7,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class Model3(nn.Module):\n","    def __init__(self):\n","        super(Model3, self).__init__()\n","        self.fc1 = nn.Linear(12, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 1)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp_model3 = Model3()\n"],"metadata":{"id":"2Cq9y6cvPAYQ","executionInfo":{"status":"ok","timestamp":1725931273081,"user_tz":-540,"elapsed":5,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","#criterion = nn.CrossEntropyLoss()\n","criterion = nn.BCEWithLogitsLoss()\n","\n","optimizer1 = optim.SGD(mlp_model1.parameters(), lr=0.01)\n","optimizer2 = optim.SGD(mlp_model2.parameters(), lr=0.01)\n","optimizer3 = optim.SGD(mlp_model3.parameters(), lr=0.01)\n"],"metadata":{"id":"C1yoveDPPESh","executionInfo":{"status":"ok","timestamp":1725931273081,"user_tz":-540,"elapsed":5,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer1.zero_grad()\n","        outputs = mlp_model1(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer1.step()\n","        running_loss += loss.item()\n","    print(f\"MLP Model 1, Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWF2uYjLPFCJ","outputId":"9d289f06-e08d-4cf9-b792-807bb2557c76","executionInfo":{"status":"ok","timestamp":1725931273784,"user_tz":-540,"elapsed":708,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Model 1, Epoch 1, Loss: 0.6210300035592986\n","MLP Model 1, Epoch 2, Loss: 0.5691991971760262\n","MLP Model 1, Epoch 3, Loss: 0.5206249130935203\n","MLP Model 1, Epoch 4, Loss: 0.4678667209497312\n","MLP Model 1, Epoch 5, Loss: 0.40986978389867923\n"]}]},{"cell_type":"code","source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer2.zero_grad()\n","        outputs = mlp_model2(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer2.step()\n","        running_loss += loss.item()\n","    print(f\"MLP Model 2, Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiJcnPaKPIIz","outputId":"22d44c83-9159-4dd1-dfa3-cc64f143f512","executionInfo":{"status":"ok","timestamp":1725931274122,"user_tz":-540,"elapsed":340,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Model 2, Epoch 1, Loss: 0.7102951429239134\n","MLP Model 2, Epoch 2, Loss: 0.6356095707998043\n","MLP Model 2, Epoch 3, Loss: 0.5813479278145767\n","MLP Model 2, Epoch 4, Loss: 0.5367427915334702\n","MLP Model 2, Epoch 5, Loss: 0.4933891354537592\n"]}]},{"cell_type":"code","source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer3.zero_grad()\n","        outputs = mlp_model3(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer3.step()\n","        running_loss += loss.item()\n","    print(f\"MLP Model 3, Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G57l9xP1PI2h","outputId":"ce2e6fc9-437f-4be7-91b4-922e69d8fc98","executionInfo":{"status":"ok","timestamp":1725931274840,"user_tz":-540,"elapsed":720,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Model 3, Epoch 1, Loss: 0.7432344017959223\n","MLP Model 3, Epoch 2, Loss: 0.6408882039349254\n","MLP Model 3, Epoch 3, Loss: 0.5676129747454713\n","MLP Model 3, Epoch 4, Loss: 0.49649881517014854\n","MLP Model 3, Epoch 5, Loss: 0.41635343105327793\n"]}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","models = [mlp_model1, mlp_model2, mlp_model3]\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = [model(inputs) for model in models]\n","        outputs = torch.mean(torch.stack(outputs), dim=0)\n","        outputs = torch.sigmoid(outputs)\n","        predicted = (outputs >= 0.5).long().squeeze()\n","        labels = labels.view_as(predicted)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f'Ensemble Accuracy: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kYw8XZZZ9jZ","outputId":"7c192845-60ee-48a1-fe92-1c7f903172c0","executionInfo":{"status":"ok","timestamp":1725931274840,"user_tz":-540,"elapsed":4,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Ensemble Accuracy: 78.92%\n"]}]},{"cell_type":"markdown","source":["### 실습2) 와인데이터를 통한 MLP 모델 3개 퀄리티 분류 앙상블\n","10진 분류\n","\n","각 모델을 튜닝하여 성능을 높여보자."],"metadata":{"id":"TqlkgaKRaq4y"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","data = pd.read_csv('wine.csv')\n","\n","data['quality'] = LabelEncoder().fit_transform(data['quality'])"],"metadata":{"id":"RvPiXEvmavly","executionInfo":{"status":"ok","timestamp":1725931274840,"user_tz":-540,"elapsed":3,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["X = data.drop(columns=['quality']).values\n","y = data['quality'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","scaler = RobustScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.long)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"QNR-dp7Iaxjy","executionInfo":{"status":"ok","timestamp":1725931274841,"user_tz":-540,"elapsed":3,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class Model1(nn.Module):\n","    def __init__(self):\n","        super(Model1, self).__init__()\n","        self.fc1 = nn.Linear(12, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 7)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp_model1 = Model1()\n"],"metadata":{"id":"Wkyl69Tfaz1m","executionInfo":{"status":"ok","timestamp":1725931275226,"user_tz":-540,"elapsed":5,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class Model2(nn.Module):\n","    def __init__(self):\n","        super(Model2, self).__init__()\n","        self.fc1 = nn.Linear(12, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 7)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp_model2 = Model2()\n"],"metadata":{"id":"10tRtgDma0PT","executionInfo":{"status":"ok","timestamp":1725931275226,"user_tz":-540,"elapsed":4,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["class Model3(nn.Module):\n","    def __init__(self):\n","        super(Model3, self).__init__()\n","        self.fc1 = nn.Linear(12, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 7)\n","\n","    def forward(self, x):\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","mlp_model3 = Model3()\n"],"metadata":{"id":"hAmS3opHa0kL","executionInfo":{"status":"ok","timestamp":1725931275226,"user_tz":-540,"elapsed":4,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer1 = optim.SGD(mlp_model1.parameters(), lr=0.01)\n","optimizer2 = optim.SGD(mlp_model2.parameters(), lr=0.01)\n","optimizer3 = optim.SGD(mlp_model3.parameters(), lr=0.01)\n"],"metadata":{"id":"i8HugoUaa7Ka","executionInfo":{"status":"ok","timestamp":1725931275226,"user_tz":-540,"elapsed":4,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer1.zero_grad()\n","        outputs = mlp_model1(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer1.step()\n","        running_loss += loss.item()\n","    print(f\"MLP Model 1, Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOTTLG-Ta-CD","outputId":"4479eeac-cb4a-4000-eb88-66b12570154d","executionInfo":{"status":"ok","timestamp":1725931276048,"user_tz":-540,"elapsed":825,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Model 1, Epoch 1, Loss: 1.9167938552251675\n","MLP Model 1, Epoch 2, Loss: 1.748979613548372\n","MLP Model 1, Epoch 3, Loss: 1.6129030294534636\n","MLP Model 1, Epoch 4, Loss: 1.5007749708687388\n","MLP Model 1, Epoch 5, Loss: 1.417306241465778\n"]}]},{"cell_type":"code","source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer2.zero_grad()\n","        outputs = mlp_model2(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer2.step()\n","        running_loss += loss.item()\n","    print(f\"MLP Model 2, Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JIBIwTPa-WC","outputId":"85c85610-e58d-4ac4-ef7d-6b8d7071e35c","executionInfo":{"status":"ok","timestamp":1725931276421,"user_tz":-540,"elapsed":375,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Model 2, Epoch 1, Loss: 1.9012535795932863\n","MLP Model 2, Epoch 2, Loss: 1.697943347256358\n","MLP Model 2, Epoch 3, Loss: 1.5384097724426082\n","MLP Model 2, Epoch 4, Loss: 1.436174023442152\n","MLP Model 2, Epoch 5, Loss: 1.3757931037646969\n"]}]},{"cell_type":"code","source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer3.zero_grad()\n","        outputs = mlp_model3(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer3.step()\n","        running_loss += loss.item()\n","    print(f\"MLP Model 3, Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-aV5j4Ta-4x","outputId":"bff73bc4-e387-4998-f582-8d6da4e5b4b0","executionInfo":{"status":"ok","timestamp":1725931276801,"user_tz":-540,"elapsed":382,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Model 3, Epoch 1, Loss: 1.7896134896976192\n","MLP Model 3, Epoch 2, Loss: 1.606999965702615\n","MLP Model 3, Epoch 3, Loss: 1.4687375208226645\n","MLP Model 3, Epoch 4, Loss: 1.3843883217834845\n","MLP Model 3, Epoch 5, Loss: 1.3337490878454068\n"]}]},{"cell_type":"code","source":["models = [mlp_model1, mlp_model2, mlp_model3]\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = [model(inputs) for model in models]\n","        outputs = torch.mean(torch.stack(outputs), dim=0)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","accuracy = 100 * correct / total\n","print(f'Ensemble Accuracy: {accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z72XQX1LbJux","outputId":"d8709552-62c1-488a-b3ff-fcf444f43379","executionInfo":{"status":"ok","timestamp":1725931276802,"user_tz":-540,"elapsed":4,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Ensemble Accuracy: 47.46%\n"]}]},{"cell_type":"markdown","source":["### 2. 멀티모달 학습\n","\n","1. MNIST 이미지와 벡터화된 MNIST 이미지를 CNN과 MLP로 특징 추출\n","2. 그 후, 두가지 피처벡터를 합친다음에 FC로 최종 아웃풋 내는 모델에 전달"],"metadata":{"id":"KOCB_K1Nd_Vx"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","batch_size = 64\n","learning_rate = 0.001\n","num_epochs = 10\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# CNN\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 7 * 7)\n","        x = F.relu(self.fc1(x))\n","        return x\n","\n","# MLP\n","class MLP(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        return x\n","\n","# 멀티모달모델\n","class MultimodalModel(nn.Module):\n","    def __init__(self, cnn_model, mlp_model, combined_hidden_size, num_classes):\n","        super(MultimodalModel, self).__init__()\n","        self.cnn = cnn_model  # 위에 정의한 CNN모델 인스턴스 들어올것임. 아웃풋 128\n","        self.mlp = mlp_model  # 위에 정의한 MLP모델 인스턴스 들어올것임. 아웃풋 128\n","\n","                              # cnn_model과 mlp_model이 내뱉은 두개의 아웃풋 피처 벡터를\n","                              # 병합해서 넣어줘야 하니까 128 + 128 인풋사이즈를 가져야한다.\n","                              # cobined_hidden_size는 그냥 사용자가 설정하는 멀티모달 fc히든사이즈\n","        self.fc_combined = nn.Linear(128 + 128, combined_hidden_size)\n","                              # 아웃풋 레이어 정의, 클래스 갯수만큼 출력을 정의\n","        self.fc_out = nn.Linear(combined_hidden_size, num_classes)\n","\n","    def forward(self, image, flat_image):\n","        image_features = self.cnn(image) # CNN으로 이미지 피처 추출\n","        flat_image_features = self.mlp(flat_image) # mlp로 정형 피처 추출\n","\n","                          # 그 두 피처를 가로 방향으로 concatenate함\n","        combined = torch.cat((image_features, flat_image_features), dim=1)\n","\n","                         # 합친 피처를 은닉층에 넣고\n","        x = F.relu(self.fc_combined(combined))\n","                         # 마지막 레이어를 거쳐서 최종 아웃풋을 냄\n","        x = self.fc_out(x)\n","        return x\n","\n","cnn_model = CNN()\n","mlp_model = MLP(input_size=784, hidden_size=128)  # 28x28 이미지를 펼친 후 784차원 입력\n","multimodal_model = MultimodalModel(cnn_model, mlp_model, combined_hidden_size=128, num_classes=10)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(multimodal_model.parameters(), lr=learning_rate)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","multimodal_model = multimodal_model.to(device)\n","\n","for epoch in range(num_epochs):\n","    multimodal_model.train()\n","    running_loss = 0.0\n","\n","    for images, labels in tqdm(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # 이미지를 펼쳐서 정형 데이터로 변환\n","        flat_images = images.view(images.size(0), -1).to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = multimodal_model(images, flat_images)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n","\n","\n","    multimodal_model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(test_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            # 이미지를 펼쳐서 정형 데이터로 변환\n","            flat_images = images.view(images.size(0), -1).to(device)\n","\n","            outputs = multimodal_model(images, flat_images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f'Validation Accuracy: {accuracy:.2f}%')\n"],"metadata":{"id":"_OSrd_YV6WY4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0579ad88-3a9c-4bbd-8528-25578c32bfe6","executionInfo":{"status":"ok","timestamp":1725929237723,"user_tz":-540,"elapsed":225445,"user":{"displayName":"김우진","userId":"03388991008972650529"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:01<00:00, 6613438.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 491789.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 4467863.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 4347450.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:24<00:00, 38.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.1991\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 63.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 97.95%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:18<00:00, 49.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/10], Loss: 0.0518\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:03<00:00, 39.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.43%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:22<00:00, 41.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/10], Loss: 0.0369\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 55.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.94%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:17<00:00, 53.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/10], Loss: 0.0287\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 54.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.75%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:16<00:00, 56.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/10], Loss: 0.0216\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 68.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.81%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:17<00:00, 54.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/10], Loss: 0.0180\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 54.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.84%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:16<00:00, 57.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/10], Loss: 0.0143\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 59.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.78%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:16<00:00, 55.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/10], Loss: 0.0135\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 66.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.88%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:16<00:00, 57.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/10], Loss: 0.0104\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 68.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 99.03%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 938/938 [00:17<00:00, 54.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Loss: 0.0085\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:02<00:00, 69.58it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 98.97%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Hv1L5FhtYrpH"},"execution_count":null,"outputs":[]}]}